{
    "model_type": "causal",
    "model_path": "HarshalH/alpaca_opt",
    "model_id": "alpaca_opt",
    "reencoder": "average_word_embeddings_komninos",
    "truncate_to_length": 400,
    "max_input_length": 256,
    "dtype": "float32",
    "seed": 42,
    "use_flash_attention_2": false,
    "generation_configs": {
        "num_beams": 1,
        "max_new_tokens": 20,
        "do_sample": false
    },
    "batch_size": 16,
    "disable_instruction": false,
    "pattern": "### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:"
}